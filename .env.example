# Django Production Settings
# Generate a new secret key: python -c "import secrets; print(secrets.token_urlsafe(50))"
SECRET_KEY=your-secret-key-here-generate-a-new-one
DEBUG=False
ALLOWED_HOSTS=localhost,127.0.0.1,yourdomain.com

# LLM Provider Configuration
# Options: 'groq' (free, cloud - recommended for deployment), 'ollama' (free, local), 'none' (rule-based)
# Default: 'groq' (FREE, works on all cloud platforms!)
LLM_PROVIDER=groq

# Groq Configuration (FREE, Cloud-Based - Works on Railway, Render, etc!)
# Get your free API key from: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile
# Other Groq models: mixtral-8x7b-32768, gemma2-9b-it, llama-3.1-8b-instant

# Ollama Configuration (FREE - Local Only, requires Ollama installation)
# Only use if you're self-hosting on a VPS
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral
# Other Ollama models: llama3, gemma, phi, qwen
# To see available models: ollama list
# To download a model: ollama pull llama3

# Enable/Disable LLM for flashcard generation
# Set to 'true' to use LLM, 'false' to use rule-based generation
USE_LLM=true

# Flashcard Generation Settings
# Number of flashcards to generate per file (default: 20)
DEFAULT_FLASHCARDS_COUNT=20

